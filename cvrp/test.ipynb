{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.distributions import Categorical, kl\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "# from d2l.torch import Animator\n",
    "\n",
    "from net_deepaco import Net as Net_DeepACO\n",
    "from net import Net\n",
    "from aco import ACO\n",
    "from faco import FACO\n",
    "from utils import gen_pyg_data, load_test_dataset\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "EPS = 1e-10\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.parsers.expat import model\n",
    "\n",
    "from copy import copy\n",
    "from train import attach_faco_state_to_pyg\n",
    "from utils import gen_pyg_data, load_test_dataset\n",
    "\n",
    "\n",
    "MIN_NEW_EDGES = 8\n",
    "K_NEAREST = 20\n",
    "SAMPLE_TWO_OPT = True\n",
    "INV_TEMP = 1.0\n",
    "T_eval = 5\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_instance(model, demands, distances, n_ants, t_aco_diff, visualize=False):\n",
    "    model.eval()\n",
    "    pyg_base = gen_pyg_data(demands, distances, device)\n",
    "    results = torch.zeros(size=(len(t_aco_diff),), device=device)\n",
    "\n",
    "    solver = FACO(\n",
    "        distances=distances,\n",
    "        demand=demands,\n",
    "        n_ants=n_ants,\n",
    "        k_nearest=K_NEAREST,\n",
    "        capacity=50,\n",
    "        decay=0.9,\n",
    "        alpha=1.0,\n",
    "        beta=1.0,\n",
    "        min_new_edges=MIN_NEW_EDGES,\n",
    "        sample_two_opt=SAMPLE_TWO_OPT,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        fig.suptitle('Heuristic Matrix Evolution')\n",
    "        cbar1, cbar2 = None, None\n",
    "\n",
    "    # baseline (first step sampling mean)\n",
    "    ref_flat = solver.best_flat.copy()\n",
    "    tau = solver.pheromone_sparse.detach().clone()\n",
    "    pyg = copy(pyg_base)\n",
    "    pyg = attach_faco_state_to_pyg(pyg, solver, ref_flat, tau, net=model)\n",
    "    out = model(pyg)\n",
    "    heu_vec = out\n",
    "    heu_full = model.reshape(pyg, heu_vec) + 1e-10\n",
    "    solver.set_heuristic(heu_full)\n",
    "\n",
    "    costs_np, flats, _touched = solver.sample(invtemp=INV_TEMP, require_prob=False)\n",
    "\n",
    "    T_eval = t_aco_diff[-1]\n",
    "    for _t in range(T_eval):\n",
    "        ref_flat = solver.best_flat.copy()\n",
    "        tau = solver.pheromone_sparse.detach().clone()\n",
    "\n",
    "        pyg = copy(pyg_base)\n",
    "        pyg = attach_faco_state_to_pyg(pyg, solver, ref_flat, tau, net=model)\n",
    "\n",
    "        out = model(pyg)\n",
    "        heu_vec = out\n",
    "        heu_full = model.reshape(pyg, heu_vec) + 1e-10\n",
    "        solver.set_heuristic(heu_full)\n",
    "\n",
    "        if visualize:\n",
    "            # Remove old colorbars if they exist\n",
    "            if cbar1 is not None:\n",
    "                cbar1.remove()\n",
    "            if cbar2 is not None:\n",
    "                cbar2.remove()\n",
    "            \n",
    "            # Clear previous plots\n",
    "            for ax in axes:\n",
    "                ax.clear()\n",
    "            \n",
    "            # Plot heuristic matrix\n",
    "            heu_cpu = heu_full.cpu().numpy()\n",
    "            im1 = axes[0].imshow(heu_cpu, cmap='viridis', aspect='auto')\n",
    "            axes[0].set_title(f'Heuristic Matrix (Iteration {_t+1})')\n",
    "            axes[0].set_xlabel('To Node')\n",
    "            axes[0].set_ylabel('From Node')\n",
    "            cbar1 = plt.colorbar(im1, ax=axes[0])\n",
    "            \n",
    "            # Plot pheromone matrix (convert sparse to dense for visualization)\n",
    "            tau_dense = tau.to_dense().cpu().numpy() if hasattr(tau, 'to_dense') else tau.cpu().numpy()\n",
    "            im2 = axes[1].imshow(tau_dense, cmap='hot', aspect='auto')\n",
    "            axes[1].set_title(f'Pheromone Matrix (Iteration {_t+1})')\n",
    "            axes[1].set_xlabel('To Node')\n",
    "            axes[1].set_ylabel('From Node')\n",
    "            cbar2 = plt.colorbar(im2, ax=axes[1])\n",
    "            \n",
    "            # Update display\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            plt.pause(0.1)\n",
    "\n",
    "        costs_np, flats, _touched = solver.sample(invtemp=INV_TEMP, require_prob=False)\n",
    "        best_i = int(np.argmin(costs_np))\n",
    "        best_cost = float(costs_np[best_i])\n",
    "        best_flat = flats[best_i]\n",
    "\n",
    "        if best_cost < solver.best_cost:\n",
    "            solver.best_cost = best_cost\n",
    "            solver.best_flat = best_flat\n",
    "        solver._update_pheromone_from_flat(best_flat, best_cost)\n",
    "\n",
    "        # Check if (_t + 1) is in t_aco_diff and get its index\n",
    "        if (_t + 1) in t_aco_diff:\n",
    "            i = t_aco_diff.index(_t + 1)\n",
    "            results[i] = solver.best_cost\n",
    "\n",
    "    if visualize:\n",
    "        plt.close(fig)\n",
    "    \n",
    "    return results\n",
    "        \n",
    "@torch.no_grad()\n",
    "def infer_instance_deepaco(model, demands, distances, n_ants, t_aco_diff):\n",
    "    if model:\n",
    "        model.eval()\n",
    "        pyg_data = gen_pyg_data(demands, distances, device)\n",
    "        heu_vec = model(pyg_data)\n",
    "        heu_mat = model.reshape(pyg_data, heu_vec) + EPS\n",
    "        aco = ACO(\n",
    "            distances=distances,\n",
    "            demand=demands,\n",
    "            n_ants=n_ants,\n",
    "            heuristic=heu_mat,\n",
    "            device=device\n",
    "        )\n",
    "    else:\n",
    "        aco = ACO(\n",
    "            distances=distances,\n",
    "            demand=demands,\n",
    "            n_ants=n_ants,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "    results = torch.zeros(size=(len(t_aco_diff),), device=device)\n",
    "    for i, t in enumerate(t_aco_diff):\n",
    "        best_cost = aco.run(t)\n",
    "        results[i] = best_cost\n",
    "    return results\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dataset, model, n_ants, t_aco, visualize=False):\n",
    "    # _t_aco = [0] + t_aco\n",
    "    # t_aco_diff = [_t_aco[i+1]-_t_aco[i] for i in range(len(_t_aco)-1)]\n",
    "    sum_results = torch.zeros(size=(len(t_aco),), device=device)\n",
    "    bar = tqdm(dataset, dynamic_ncols=True)\n",
    "    start = time.time()\n",
    "    for idx, (demands, distances) in enumerate(bar):\n",
    "        # Only visualize the first instance if requested\n",
    "        viz = visualize and idx == 0\n",
    "        results = infer_instance(model, demands, distances, n_ants, t_aco, visualize=viz)\n",
    "        sum_results += results\n",
    "        bar.set_description(f'Avg costs: {(sum_results/(bar.n)).cpu().numpy()}')\n",
    "    end = time.time()\n",
    "    \n",
    "    return sum_results / len(dataset), end-start\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_deepaco(dataset, model, n_ants, t_aco):\n",
    "    _t_aco = [0] + t_aco\n",
    "    t_aco_diff = [_t_aco[i+1]-_t_aco[i] for i in range(len(_t_aco)-1)]\n",
    "    sum_results = torch.zeros(size=(len(t_aco_diff),), device=device)\n",
    "    bar = tqdm(dataset, dynamic_ncols=True)\n",
    "    start = time.time()\n",
    "    for demands, distances in bar:\n",
    "        results = infer_instance_deepaco(model, demands, distances, n_ants, t_aco_diff)\n",
    "        sum_results += results\n",
    "        bar.set_description(f'Avg costs: {(sum_results/(bar.n)).cpu().numpy()}')\n",
    "    end = time.time()\n",
    "    \n",
    "    return sum_results / len(dataset), end-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on TSP20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22b09dba25a4af1918c4054d09b87f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  72.1379771232605\n",
      "T=1, average obj. is 5.210780143737793.\n",
      "T=10, average obj. is 4.714725017547607.\n",
      "T=50, average obj. is 4.646577835083008.\n",
      "T=100, average obj. is 4.6398162841796875.\n"
     ]
    }
   ],
   "source": [
    "n_ants = 20\n",
    "n_node = 20\n",
    "k_sparse = 10\n",
    "t_aco = [1, 10, 50, 100]\n",
    "test_list = load_test_dataset(n_node, device)\n",
    "\n",
    "net = Net(value_head=True).to(device)\n",
    "net.load_state_dict(torch.load(f'../pretrained/cvrp/faco_cvrp{n_node}_ppo_nstep.pt', map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net, n_ants, t_aco, visualize=False)\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    print(\"T={}, average obj. is {}.\".format(t, avg_aco_best[i])) \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf8529e13d14660bbc8c9b210abfcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  120.70868515968323\n",
      "T=1, average obj. is 5.081987380981445.\n",
      "T=10, average obj. is 4.84982967376709.\n",
      "T=50, average obj. is 4.803032398223877.\n",
      "T=100, average obj. is 4.793013095855713.\n"
     ]
    }
   ],
   "source": [
    "n_ants = 20\n",
    "n_node = 20\n",
    "k_sparse = 10\n",
    "t_aco = [1, 10, 50, 100]\n",
    "test_list = load_test_dataset(n_node, device)\n",
    "\n",
    "net = Net_DeepACO().to(device)\n",
    "net.load_state_dict(torch.load(f'../pretrained/cvrp/cvrp{n_node}.pt', map_location=device))\n",
    "avg_aco_best, duration = test_deepaco(test_list, net, n_ants, t_aco)\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    print(\"T={}, average obj. is {}.\".format(t, avg_aco_best[i])) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGFACO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fb521829734f26bdbe7941b0dc2663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  71.1493182182312\n",
      "T=1, average obj. is 5.239306449890137.\n",
      "T=10, average obj. is 4.719290733337402.\n",
      "T=50, average obj. is 4.617067813873291.\n",
      "T=100, average obj. is 4.609489917755127.\n"
     ]
    }
   ],
   "source": [
    "n_ants = 20\n",
    "n_node = 20\n",
    "k_sparse = 10\n",
    "t_aco = [1, 10, 50, 100]\n",
    "test_list = load_test_dataset(n_node, device)\n",
    "\n",
    "net = Net(value_head=True).to(device)\n",
    "net.load_state_dict(torch.load(f'../pretrained/cvrp/faco_cvrp{n_node}_ppo_nstep.pt', map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net, n_ants, t_aco)\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    print(\"T={}, average obj. is {}.\".format(t, avg_aco_best[i])) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c139fa7a274ace8c41604d3b6ed3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m t_aco = [\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m]\n\u001b[32m      5\u001b[39m test_list = load_test_dataset(n_node, device)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m avg_aco_best, duration = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_aco\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtotal duration: \u001b[39m\u001b[33m'\u001b[39m, duration)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(t_aco):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/NGFACO/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(dataset, model, n_ants, t_aco, visualize)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, (demands, distances) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bar):\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Only visualize the first instance if requested\u001b[39;00m\n\u001b[32m    154\u001b[39m     viz = visualize \u001b[38;5;129;01mand\u001b[39;00m idx == \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     results = \u001b[43minfer_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_aco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mviz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     sum_results += results\n\u001b[32m    157\u001b[39m     bar.set_description(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAvg costs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(sum_results/(bar.n)).cpu().numpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/NGFACO/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36minfer_instance\u001b[39m\u001b[34m(model, demands, distances, n_ants, t_aco_diff, visualize)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer_instance\u001b[39m(model, demands, distances, n_ants, t_aco_diff, visualize=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m()\n\u001b[32m     17\u001b[39m     pyg_base = gen_pyg_data(demands, distances, device)\n\u001b[32m     18\u001b[39m     results = torch.zeros(size=(\u001b[38;5;28mlen\u001b[39m(t_aco_diff),), device=device)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "n_ants = 20\n",
    "n_node = 20\n",
    "k_sparse = 10\n",
    "t_aco = [1, 10, 50, 100]\n",
    "test_list = load_test_dataset(n_node, device)\n",
    "\n",
    "\n",
    "avg_aco_best, duration = test(test_list, None, n_ants, t_aco)\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    print(\"T={}, average obj. is {}.\".format(t, avg_aco_best[i]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Visualization (Single Instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m k_sparse = \u001b[32m10\u001b[39m\n\u001b[32m      4\u001b[39m t_aco = [\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m test_list = \u001b[43mload_test_dataset\u001b[49m(n_node, device)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m      8\u001b[39m net = Net(value_head=\u001b[38;5;28;01mTrue\u001b[39;00m).to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "n_ants = 20\n",
    "n_node = 20\n",
    "k_sparse = 10\n",
    "t_aco = [1, 10, 50, 100]\n",
    "test_list = load_test_dataset(n_node, device)\n",
    "\n",
    "# Load model\n",
    "net = Net(value_head=True).to(device)\n",
    "net.load_state_dict(torch.load(f'../pretrained/cvrp/faco_cvrp{n_node}_ppo_nstep.pt', map_location=device))\n",
    "\n",
    "# Test with visualization enabled (will only visualize first instance)\n",
    "avg_aco_best, duration = test(test_list[:1], net, n_ants, t_aco, visualize=True)\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    print(\"T={}, average obj. is {:.2f}.\".format(t, avg_aco_best[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGFACO (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
